{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Run SuperPrompt-v1 AI Model WEB UI\n",
        "\n",
        "Make your prompts better for AI Art or in general!\n",
        "\n",
        "Used Model: https://huggingface.co/roborovski/superprompt-v1\n",
        "\n",
        "Blog Model: https://brianfitzgerald.xyz/prompt-augmentation/\n",
        "\n",
        "Google Colab Notebook Made by [Nick088](https://linktr.ee/Nick088)"
      ],
      "metadata": {
        "id": "rhAucpX5Li7V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install & Load Dependencies, Model\n",
        "\n",
        "#@markdown If you wanna use CPU (slower, no daily limit): Set the CPU from Edit -> Notebook Settings -> CPU\n",
        "\n",
        "#@markdown If you wanna use GPU (faster, max 12 free hours daily limit): Set the Video Card from Edit -> Notebook Settings -> T4 GPU OR Any other GPUs based on your Google Colab Subscription\n",
        "\n",
        "#@markdown Anyways its a very small model, it doesn't matter much if you use cpu or gpu.\n",
        "!pip install transformers\n",
        "!pip install einops\n",
        "!pip install accelerate\n",
        "!pip install sentencepiece\n",
        "!pip install gradio\n",
        "import gradio as gr\n",
        "import torch\n",
        "from IPython.display import clear_output\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = \"cuda\"\n",
        "    print(\"Using GPU\")\n",
        "else:\n",
        "    device = \"cpu\"\n",
        "    print(\"Using CPU\")\n",
        "\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-small\")\n",
        "model = T5ForConditionalGeneration.from_pretrained(\"roborovski/superprompt-v1\", torch_dtype=torch.float16)\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "clear_output()\n",
        "print(f\"Downloaded SuperPrompt-v1\")\n"
      ],
      "metadata": {
        "id": "GyK68jfLe5gy",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Run UI\n",
        "\n",
        "def answer(input_text, max_new_tokens, repetition_penalty, temperature, top_p, top_k, seed):\n",
        "  torch.manual_seed(seed)\n",
        "  input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.to(device)\n",
        "  outputs = model.generate(input_ids, max_new_tokens=max_new_tokens, repetition_penalty=repetition_penalty, do_sample=True, temperature=temperature, top_p=top_p, top_k=top_k)\n",
        "\n",
        "  # Extract the generated text from the model output\n",
        "  dirty_text = tokenizer.decode(outputs[0])\n",
        "  text = dirty_text.replace(\"<pad>\", \"\").replace(\"</s>\", \"\")\n",
        "  return text\n",
        "\n",
        "# Define the gradio interface\n",
        "interface = gr.Interface(\n",
        "    fn=answer,\n",
        "    inputs=[\n",
        "        gr.Textbox(lines=2, label=\"Your Prompt\"),\n",
        "        gr.Slider(value=512, minimum=250, maximum=512, step=1, interactive=True, label=\"Max New Tokens\", info=\"The maximum numbers of new tokens, controls how long is the output\"),\n",
        "        gr.Slider(value=1.2, minimum=0, maximum=2, step=0.05, interactive=True, label=\"Repetition Penalty\", info=\"Penalize repeated tokens, making the AI repeat less itself\"),\n",
        "        gr.Slider(value=0.5, minimum=0, maximum=1, step=0.05, interactive=True, label=\"Temperature\", info=\"Higher values produce more diverse outputs\"),\n",
        "        gr.Slider(value=1, minimum=0, maximum=2, step=0.05, interactive=True, label=\"Top P\", info=\"Higher values sample more low-probability tokens\"),\n",
        "        gr.Slider(value=1, minimum=1, maximum=100, step=1, interactive=True, label=\"Top K\", info=\"Higher k means more diverse outputs by considering a range of tokens\"),\n",
        "        gr.Number(value=42, interactive=True, label=\"Seed\", info=\"A starting point to initiate the generation process\"),\n",
        "    ],\n",
        "    outputs=\"text\",\n",
        "    title=\"SuperPrompt-v1\",\n",
        ")\n",
        "\n",
        "\n",
        "# Launch the gradio interface\n",
        "interface.launch(share=True, debug=True)"
      ],
      "metadata": {
        "id": "4901EHafGkhK",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}