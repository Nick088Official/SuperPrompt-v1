{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Run SuperPrompt-v1 AI Model Ipywidgets UI\n",
        "\n",
        "Make your prompts better for AI Art or in general!\n",
        "\n",
        "[Used Model](https://huggingface.co/roborovski/superprompt-v1)\n",
        "\n",
        "[Model Blog](https://brianfitzgerald.xyz/prompt-augmentation/)\n",
        "\n",
        "Google Colab Notebook Made by [Nick088](https://linktr.ee/Nick088) using Ipywidgets UI which is allowed on Google Colab"
      ],
      "metadata": {
        "id": "rhAucpX5Li7V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install\n",
        "\n",
        "#@markdown If you wanna use CPU (slower, max 12 free hours daily limit): Set the CPU from Edit -> Notebook Settings -> CPU\n",
        "\n",
        "#@markdown If you wanna use GPU (faster, max 12 free hours daily limit): Set the Video Card from Edit -> Notebook Settings -> T4 GPU OR Any other GPUs based on your Google Colab Subscription\n",
        "\n",
        "#@markdown Anyways its a very small model, it doesn't matter much if you use cpu or gpu.\n",
        "\n",
        "import torch\n",
        "from IPython.display import clear_output\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = \"cuda\"\n",
        "    print(\"Using GPU\")\n",
        "else:\n",
        "    device = \"cpu\"\n",
        "    print(\"Using CPU\")\n",
        "\n",
        "!git clone https://github.com/Nick088Official/SuperPrompt-v1.git\n",
        "%cd SuperPrompt-v1/Scripts\n",
        "!pip install -r requirements_no_ui.txt\n",
        "# ipywidgets ui\n",
        "!pip install ipywidgets\n",
        "!jupyter nbextension enable --py widgetsnbextension\n",
        "from ipywidgets import widgets\n",
        "from ipywidgets import Layout\n",
        "\n",
        "clear_output()\n",
        "print(f\"Downloaded SuperPrompt-v1 on {'GPU' if device == 'cuda' else 'CPU'}\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "CJKumDcSxPhy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Run ipywidgets UI\n",
        "\n",
        "# style to fix too long descriptions\n",
        "style = {'description_width': 'initial'}\n",
        "\n",
        "\n",
        "# Create the your prompt widget\n",
        "your_prompt_widget = widgets.Text(\n",
        "    value=\"A storefront with 'Text to Image' written on it.\",\n",
        "    placeholder='Type your prompt here',\n",
        "    description='Your Prompt:',\n",
        "    disabled=False,\n",
        "    style=style,\n",
        "    layout=Layout(width='480px', height='50px')\n",
        ")\n",
        "\n",
        "# Create the task prefix widget\n",
        "task_prefix_widget = widgets.Text(\n",
        "    value=\"Expand the following prompt to add more detail\",\n",
        "    placeholder='Type your task prefix here',\n",
        "    description='Task Prefix (The prompt prefix for how the AI should make yours better):',\n",
        "    disabled=False,\n",
        "    style=style,\n",
        "    layout=Layout(width='750px', height='50px')\n",
        ")\n",
        "\n",
        "# Create the model precision type dropdown menu\n",
        "model_precision_type_widget = widgets.Dropdown(\n",
        "    options=['fp16', 'fp32'],\n",
        "    value='fp16',\n",
        "    description='Model Precision Type (The precision type to load the model, like fp16 which is faster, or fp32 which is more precise but more resource consuming):',\n",
        "    disabled=False,\n",
        "    style=style,\n",
        "    layout=Layout(width='925px', height='50px')\n",
        ")\n",
        "\n",
        "# Create the max_new_tokens slider\n",
        "max_new_tokens_widget = widgets.IntSlider(\n",
        "    value=512,\n",
        "    min=250,\n",
        "    max=512,\n",
        "    step=1,\n",
        "    description='Max New Tokens (Maximum number of the tokens to generate, controls how long is the text):',\n",
        "    disabled=False,\n",
        "    continuous_update=False,\n",
        "    orientation='horizontal',\n",
        "    readout=True,\n",
        "    readout_format='d',\n",
        "    style=style,\n",
        "    layout=Layout(width='800px', height='50px')\n",
        ")\n",
        "\n",
        "# Create the repetition_penalty slider\n",
        "repetition_penalty_widget = widgets.FloatSlider(\n",
        "    value=1.2,\n",
        "    min=0.0,\n",
        "    max=2.0,\n",
        "    step=0.05,\n",
        "    description='Repetition Penalty (Penalize repeated tokens, so makes the AI repeat less of itself):',\n",
        "    disabled=False,\n",
        "    continuous_update=False,\n",
        "    orientation='horizontal',\n",
        "    readout=True,\n",
        "    readout_format='.2f',\n",
        "    style=style,\n",
        "    layout=Layout(width='800px', height='50px')\n",
        ")\n",
        "\n",
        "# Create the temperature slider\n",
        "temperature_widget = widgets.FloatSlider(\n",
        "    value=0.5,\n",
        "    min=0.0,\n",
        "    max=1.00,\n",
        "    step=0.05,\n",
        "    description='Temperature (Higher values produce more diverse outputs):',\n",
        "    disabled=False,\n",
        "    continuous_update=False,\n",
        "    orientation='horizontal',\n",
        "    readout=True,\n",
        "    readout_format='.2f',\n",
        "    style=style,\n",
        "    layout=Layout(width='700px', height='50px')\n",
        ")\n",
        "\n",
        "# Create the top_p slider\n",
        "top_p_widget = widgets.FloatSlider(\n",
        "    value=1.0,\n",
        "    min=0.0,\n",
        "    max=2.0,\n",
        "    step=0.05,\n",
        "    description='Top P (Higher values sample more low-probability tokens):',\n",
        "    disabled=False,\n",
        "    continuous_update=False,\n",
        "    orientation='horizontal',\n",
        "    readout=True,\n",
        "    readout_format='.2f',\n",
        "    style=style,\n",
        "    layout=Layout(width='600px', height='50px')\n",
        ")\n",
        "\n",
        "# Create the top_k slider\n",
        "top_k_widget = widgets.IntSlider(\n",
        "    value=1,\n",
        "    min=1,\n",
        "    max=100,\n",
        "    step=1,\n",
        "    description='Top K (Higher k means more diverse outputs by considering a range of tokens):',\n",
        "    disabled=False,\n",
        "    continuous_update=False,\n",
        "    orientation='horizontal',\n",
        "    readout=True,\n",
        "    readout_format='d',\n",
        "    style=style,\n",
        "    layout=Layout(width='700px', height='50px')\n",
        ")\n",
        "\n",
        "# Create the seed input\n",
        "seed_widget = widgets.IntSlider(\n",
        "    value=42,\n",
        "    min=0,\n",
        "    max=4294967295,\n",
        "    description='Seed (Starting point to initiate the generation process, put 0 for random):',\n",
        "    disabled=False,\n",
        "    continuous_update=False,\n",
        "    orientation='horizontal',\n",
        "    readout=True,\n",
        "    readout_format='d',\n",
        "    style=style,\n",
        "    layout=Layout(width='800px', height='50px')\n",
        ")\n",
        "\n",
        "# Create the output widget\n",
        "output_widget = widgets.Output()\n",
        "\n",
        "# Define the function to handle button click\n",
        "def on_button_clicked(b):\n",
        "    with output_widget:\n",
        "      your_prompt = your_prompt_widget.value\n",
        "      task_prefix = task_prefix_widget.value\n",
        "      max_new_tokens = max_new_tokens_widget.value\n",
        "      repetition_penalty = repetition_penalty_widget.value\n",
        "      temperature = temperature_widget.value\n",
        "      model_precision_type = model_precision_type_widget.value\n",
        "      top_p = top_p_widget.value\n",
        "      top_k = top_k_widget.value\n",
        "      seed = seed_widget.value\n",
        "      command = f'install_and_run_no_ui.py \"{your_prompt}\" \"{task_prefix}\" {max_new_tokens} {repetition_penalty} {temperature} {model_precision_type} {top_p} {top_k} {seed}'\n",
        "      !python $command\n",
        "      output_widget.clear_output(wait=True)\n",
        "\n",
        "\n",
        "# Create the button widget\n",
        "button = widgets.Button(description=\"Generate Better Prompt\", layout=Layout(width='400px', height='50px'))\n",
        "button.on_click(on_button_clicked)\n",
        "\n",
        "# Create the UI layout\n",
        "ui = widgets.VBox([\n",
        "    your_prompt_widget,\n",
        "    task_prefix_widget,\n",
        "    model_precision_type_widget,\n",
        "    max_new_tokens_widget,\n",
        "    repetition_penalty_widget,\n",
        "    temperature_widget,\n",
        "    top_p_widget,\n",
        "    top_k_widget,\n",
        "    seed_widget,\n",
        "    button,\n",
        "    output_widget\n",
        "])\n",
        "\n",
        "# display ui\n",
        "ui\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "EdkzbEAnxPQG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}