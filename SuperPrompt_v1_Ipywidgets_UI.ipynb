{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Run SuperPrompt-v1 AI Model Ipywidgets UI\n",
        "\n",
        "Make your prompts better for AI Art or in general!\n",
        "\n",
        "Used Model: https://huggingface.co/roborovski/superprompt-v1\n",
        "\n",
        "Blog Model: https://brianfitzgerald.xyz/prompt-augmentation/\n",
        "\n",
        "Google Colab Notebook Made by [Nick088](https://linktr.ee/Nick088) using Ipywidgets UI which is allowed on Google Colab"
      ],
      "metadata": {
        "id": "rhAucpX5Li7V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install & Load Dependencies, Model\n",
        "\n",
        "#@markdown If you wanna use CPU (slower, no daily limit): Set the CPU from Edit -> Notebook Settings -> CPU\n",
        "\n",
        "#@markdown If you wanna use GPU (faster, max 12 free hours daily limit): Set the Video Card from Edit -> Notebook Settings -> T4 GPU OR Any other GPUs based on your Google Colab Subscription\n",
        "\n",
        "#@markdown Anyways its a very small model, it doesn't matter much if you use cpu or gpu.\n",
        "\n",
        "!pip install transformers\n",
        "!pip install einops\n",
        "!pip install accelerate\n",
        "!pip install sentencepiece\n",
        "import torch\n",
        "from IPython.display import clear_output\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "import random\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = \"cuda\"\n",
        "    print(\"Using GPU\")\n",
        "else:\n",
        "    device = \"cpu\"\n",
        "    print(\"Using CPU\")\n",
        "\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-small\")\n",
        "model = T5ForConditionalGeneration.from_pretrained(\"roborovski/superprompt-v1\", torch_dtype=torch.float16) # torch.float16 is basically fp16, so model precision in 16 bits which is faster and less resource consuming, you could also put torch.float32 which is fp32 that lods it in 32bits which is more precise but slower and more resource consuming\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "# ipywidgets ui\n",
        "!pip install ipywidgets\n",
        "!jupyter nbextension enable --py widgetsnbextension\n",
        "from ipywidgets import widgets\n",
        "from ipywidgets import Layout\n",
        "\n",
        "clear_output()\n",
        "print(f\"Downloaded & SuperPrompt-v1 on {'GPU' if device == 'cuda' else 'CPU'}\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "CJKumDcSxPhy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Run ipywidgets UI\n",
        "\n",
        "# Define the function to generate text\n",
        "def generate_text(system_prompt, your_prompt, max_new_tokens, repetition_penalty, temperature, top_p, top_k):\n",
        "    full_prompt = f\"{system_prompt}, {your_prompt}\"\n",
        "    input_ids = tokenizer(full_prompt, return_tensors=\"pt\").input_ids\n",
        "    outputs = model.generate(input_ids, max_new_tokens=max_new_tokens, repetition_penalty=repetition_penalty, do_sample=True, temperature=temperature, top_p=top_p, top_k=top_k)\n",
        "    dirty_text = tokenizer.decode(outputs[0])\n",
        "    text = dirty_text.replace(\"<pad>\", \"\").replace(\"</s>\", \"\")\n",
        "    return text\n",
        "\n",
        "\n",
        "# style to fix too long descriptions\n",
        "style = {'description_width': 'initial'}\n",
        "\n",
        "\n",
        "# Create the your prompt widget\n",
        "your_prompt_widget = widgets.Text(\n",
        "    value=\"A storefront with 'Text to Image' written on it.\",\n",
        "    placeholder='Type your prompt here',\n",
        "    description='Your Prompt:',\n",
        "    disabled=False,\n",
        "    style=style,\n",
        "    layout=Layout(width='480px', height='50px')\n",
        ")\n",
        "\n",
        "# Create the system prompt widget\n",
        "system_prompt_widget = widgets.Text(\n",
        "    value=\"Expand with as much details as possible the prompt:\",\n",
        "    placeholder='Type the system prompt here',\n",
        "    description='System Prompt (Prompt to stylize the AI):',\n",
        "    disabled=False,\n",
        "    style=style,\n",
        "    layout=Layout(width='600px', height='50px')\n",
        ")\n",
        "\n",
        "# Create the max_new_tokens slider\n",
        "max_new_tokens_widget = widgets.IntSlider(\n",
        "    value=512,\n",
        "    min=250,\n",
        "    max=512,\n",
        "    step=1,\n",
        "    description='Max New Tokens (Maximum number of the tokens to generate, controls how long is the text):',\n",
        "    disabled=False,\n",
        "    continuous_update=False,\n",
        "    orientation='horizontal',\n",
        "    readout=True,\n",
        "    readout_format='d',\n",
        "    style=style,\n",
        "    layout=Layout(width='800px', height='50px')\n",
        ")\n",
        "\n",
        "# Create the repetition_penalty slider\n",
        "repetition_penalty_widget = widgets.FloatSlider(\n",
        "    value=1.2,\n",
        "    min=0.0,\n",
        "    max=2.0,\n",
        "    step=0.05,\n",
        "    description='Repetition Penalty (Penalize repeated tokens, so makes the AI repeat less of itself):',\n",
        "    disabled=False,\n",
        "    continuous_update=False,\n",
        "    orientation='horizontal',\n",
        "    readout=True,\n",
        "    readout_format='.2f',\n",
        "    style=style,\n",
        "    layout=Layout(width='800px', height='50px')\n",
        ")\n",
        "\n",
        "# Create the temperature slider\n",
        "temperature_widget = widgets.FloatSlider(\n",
        "    value=0.5,\n",
        "    min=0.0,\n",
        "    max=1.00,\n",
        "    step=0.05,\n",
        "    description='Temperature (Higher values produce more diverse outputs):',\n",
        "    disabled=False,\n",
        "    continuous_update=False,\n",
        "    orientation='horizontal',\n",
        "    readout=True,\n",
        "    readout_format='.2f',\n",
        "    style=style,\n",
        "    layout=Layout(width='700px', height='50px')\n",
        ")\n",
        "\n",
        "# Create the top_p slider\n",
        "top_p_widget = widgets.FloatSlider(\n",
        "    value=1.0,\n",
        "    min=0.0,\n",
        "    max=2.0,\n",
        "    step=0.05,\n",
        "    description='Top P (Higher values sample more low-probability tokens):',\n",
        "    disabled=False,\n",
        "    continuous_update=False,\n",
        "    orientation='horizontal',\n",
        "    readout=True,\n",
        "    readout_format='.2f',\n",
        "    style=style,\n",
        "    layout=Layout(width='600px', height='50px')\n",
        ")\n",
        "\n",
        "# Create the top_k slider\n",
        "top_k_widget = widgets.IntSlider(\n",
        "    value=1,\n",
        "    min=1,\n",
        "    max=100,\n",
        "    step=1,\n",
        "    description='Top K (Higher k means more diverse outputs by considering a range of tokens):',\n",
        "    disabled=False,\n",
        "    continuous_update=False,\n",
        "    orientation='horizontal',\n",
        "    readout=True,\n",
        "    readout_format='d',\n",
        "    style=style,\n",
        "    layout=Layout(width='700px', height='50px')\n",
        ")\n",
        "\n",
        "# Create the seed input\n",
        "seed_widget = widgets.IntText(\n",
        "    value=42,\n",
        "    description='Seed (Starting point to initiate the generation process, put 0 for random):',\n",
        "    disabled=False,\n",
        "    continuous_update=False,\n",
        "    orientation='horizontal',\n",
        "    readout=True,\n",
        "    readout_format='d',\n",
        "    style=style,\n",
        "    layout=Layout(width='480px', height='50px')\n",
        ")\n",
        "\n",
        "# Create the output widget\n",
        "output_widget = widgets.Output()\n",
        "\n",
        "# Define the function to handle button click\n",
        "def on_button_clicked(b):\n",
        "    with output_widget:\n",
        "        output_widget.clear_output(wait=True)\n",
        "        print(\"Generating a better version of your prompt...\")\n",
        "        system_prompt = system_prompt_widget.value\n",
        "        your_prompt = your_prompt_widget.value\n",
        "        max_new_tokens = max_new_tokens_widget.value\n",
        "        repetition_penalty = repetition_penalty_widget.value\n",
        "        temperature = temperature_widget.value\n",
        "        top_p = top_p_widget.value\n",
        "        top_k = top_k_widget.value\n",
        "        seed = seed_widget.value\n",
        "        if seed == 0:\n",
        "          seed = random.randint(1, 100000)\n",
        "          torch.manual_seed(seed)\n",
        "        else:\n",
        "          torch.manual_seed(seed)\n",
        "        generated_text = generate_text(system_prompt, your_prompt, max_new_tokens, repetition_penalty, temperature, top_p, top_k)\n",
        "        output_widget.clear_output(wait=True)\n",
        "        print(generated_text)\n",
        "\n",
        "\n",
        "# Create the button widget\n",
        "button = widgets.Button(description=\"Generate Better Prompt\", layout=Layout(width='400px', height='50px'))\n",
        "button.on_click(on_button_clicked)\n",
        "\n",
        "# Create the UI layout\n",
        "ui = widgets.VBox([\n",
        "    system_prompt_widget,\n",
        "    your_prompt_widget,\n",
        "    max_new_tokens_widget,\n",
        "    repetition_penalty_widget,\n",
        "    temperature_widget,\n",
        "    top_p_widget,\n",
        "    top_k_widget,\n",
        "    seed_widget,\n",
        "    button,\n",
        "    output_widget\n",
        "])\n",
        "\n",
        "# display ui\n",
        "ui\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "EdkzbEAnxPQG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}